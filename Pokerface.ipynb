{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from distutils.core import setup\n",
    "from setuptools import find_packages\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense,BatchNormalization\n",
    "\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing BCI Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------- SETUP--------------#\n",
    "\n",
    "with open(\"README.md\", \"r\") as fh:\n",
    "    long_description = fh.read()\n",
    "\n",
    "setup(\n",
    "  name = 'pyOpenBCI',\n",
    "  packages = find_packages(),\n",
    "  version = '0.13',\n",
    "  license='MIT',\n",
    "  description = 'A lib for controlling OpenBCI devices',\n",
    "  long_description=long_description,\n",
    "  long_description_content_type=\"text/markdown\",\n",
    "  author = 'OpenBCI, Inc.',\n",
    "  author_email = 'contact@openbci.com',\n",
    "  url = 'https://github.com/andreaortuno/pyOpenBCI',\n",
    "  download_url = 'https://github.com/andreaortuno/pyOpenBCI/archive/0.13.tar.gz',\n",
    "  keywords = ['device', 'control', 'eeg', 'emg', 'ekg', 'ads1299', 'openbci', 'ganglion', 'cyton', 'wifi'],\n",
    "  install_requires=[\n",
    "          'numpy',\n",
    "          'pyserial',\n",
    "          'bitstring',\n",
    "          'xmltodict',\n",
    "          'requests',\n",
    "      ] + [\"bluepy >= 1.2\"] if sys.platform.startswith(\"linux\") else [],\n",
    "  classifiers=[\n",
    "    'Development Status :: 3 - Alpha',\n",
    "    'Intended Audience :: Developers',\n",
    "    'Topic :: Software Development :: Build Tools',\n",
    "    'License :: OSI Approved :: MIT License',\n",
    "    'Programming Language :: Python :: 3',\n",
    "    'Programming Language :: Python :: 2.7',\n",
    "    'Programming Language :: Python :: 3.4',\n",
    "    'Programming Language :: Python :: 3.6',\n",
    "  ],\n",
    ")\n",
    "\n",
    "# https://github.com/openbci-archive/pyOpenBCI/blob/master/setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Installation\n",
    "#First, make sure you have the necessary dependencies.\n",
    "\n",
    "pip install numpy pyserial bitstring xmltodict requests\n",
    "\n",
    "pip install -i https://test.pypi.org/simple/ pyOpenBCI\n",
    "#@@ -149,6 +156,8 @@ The Wifi Shield already outputs the data in Volts and the aux data in G.\n",
    "\n",
    "### Example (Print Raw Data)\n",
    "#To test this example, use `py Examples\\print_raw_example.py` or `python Examples\\print_raw_example.py`.\n",
    "\n",
    "from pyOpenBCI import OpenBCICyton\n",
    "#@@ -162,6 +171,9 @@ board.start_stream(print_raw)\n",
    "\n",
    "\n",
    "### Example (Simple LSL Streamer)\n",
    "#To run this example, use `py Examples\\lsl_example.py` or `python Examples\\lsl_example.py`.\n",
    "\n",
    "from pyOpenBCI import OpenBCICyton\n",
    "\n",
    "# https://github.com/openbci-archive/pyOpenBCI/commit/63cff4c1459434b89e8b96f3fd755b8a6673b438"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START STREAM\n",
    "\n",
    "def print_raw(sample):\n",
    "    print(sample.channels_data)\n",
    "\n",
    "board = OpenBCICyton()\n",
    "#Set (daisy = True) to stream 16 ch \n",
    "board = OpenBCICyton(daisy = False)\n",
    "\n",
    "board.start_stream(print_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn into dataframe and add timestamp column 'Time'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Emotion from EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the csv data\n",
    "eeg= pd.read_csv(r\"C:\\Users\\Zoe Mercury\\Desktop\\Iron II\\A.I\\EEG emotions.csv\" ) \n",
    "\n",
    "# Encoding the categories into numbers\n",
    "# Neg= 0  Neu= 1 Pos= 2\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(eeg['label'])\n",
    "eeg['labels']=le.transform(eeg['label'])\n",
    "eeg2=eeg.drop('label',axis=1)\n",
    "\n",
    "# Train Test Split\n",
    "X=eeg2.drop('labels',axis=1)\n",
    "y=eeg2['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 1)\n",
    "\n",
    "\n",
    "# Random Forrest Regression\n",
    "forest = RandomForestRegressor(n_estimators=12, \n",
    "                               max_depth=5,\n",
    "                               random_state=1) \n",
    "forest.fit(X_train, y_train)\n",
    "print('train accuracy was',forest.score(X_train,y_train))\n",
    "\n",
    "pred = forest.predict(X_test)\n",
    "print('test accuracy was',forest.score(X_test,y_test))\n",
    "comparison=pd.DataFrame({'observed':y_test, 'predicted':pred})\n",
    "display(comparison)\n",
    "\n",
    "\n",
    "# Save model\n",
    "pickle.dump(forest, open('C:\\\\Users\\\\Zoe Mercury\\\\Desktop\\\\Iron II\\\\A.I\\\\forest.pickle', 'wb'))\n",
    "# PermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\Zoe Mercury\\\\Desktop\\\\Iron II\\\\A.I' because I didn't add a filename+extension to the path\n",
    "\n",
    "# Load model\n",
    "forest_model = pickle.load(open('C:\\\\Users\\\\Zoe Mercury\\\\Desktop\\\\Iron II\\\\A.I\\\\forest.pickle','rb'))\n",
    "\n",
    "# Model is receiving data from OpenBCI and predicting\n",
    "# 1 brainwave input per second\n",
    "# get BCI output and convert into dataframe\n",
    "# figure out how to add a new row every instance and only predict for the new row\n",
    "# then pred= forest.predict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time Emotion Recognition via Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------Unpacking fer2013 image library----------#\n",
    "\n",
    "def create_image(column):\n",
    "    images=pd.read_csv('fer2013.csv')\n",
    "    width = 48\n",
    "    height = 48\n",
    "    a=0\n",
    "    b=0\n",
    "    c=0\n",
    "    d=0\n",
    "    e=0\n",
    "    f=0\n",
    "    g=0\n",
    "    img  = Image.new( mode = \"RGB\", size = (width, height) )\n",
    "    img.putdata(pixels)\n",
    "    if images['emotion']==0:\n",
    "        img.save('angry_'+ str(a) +'.png')\n",
    "        a +=1\n",
    "    elif images['emotion']==1:\n",
    "        img.save('disgust_'+ str(b) +'.png')\n",
    "        b +=1\n",
    "    elif images['emotion']==2:\n",
    "        img.save('fear_'+ str(c) +'.png')\n",
    "        c +=1\n",
    "    elif images['emotion']==3:\n",
    "        img.save('happy_'+ str(d) +'.png')\n",
    "        d +=1\n",
    "    elif images['emotion']==4:\n",
    "        img.save('sad_'+ str(e) +'.png')\n",
    "        e +=1\n",
    "    elif images['emotion']==5:\n",
    "        img.save('surprise_'+ str(f) +'.png')\n",
    "        f +=1\n",
    "    else:\n",
    "        img.save('neutral_'+ str(g) +'.png')\n",
    "        g +=1\n",
    "        \n",
    "images['pixels'].apply(create_image)\n",
    "\n",
    "\n",
    "# 0: -4593 images- Angry\n",
    "# 1: -547 images- Disgust\n",
    "# 2: -5121 images- Fear\n",
    "# 3: -8989 images- Happy\n",
    "# 4: -6077 images- Sad\n",
    "# 5: -4002 images- Surprise\n",
    "# 6: -6198 images- Neutral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------TRAINING THE MODEL----------------#\n",
    "# -----------Sequential Neural Network----------------#\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,kernel_size=2, input_shape=(450, 450, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(127,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(270,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(127,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(270,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64,kernel_size=2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(64)) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "# how many output categories there are\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              # expects labelEncoded input\n",
    "              # binary_crossentropy expects binary output\n",
    "              # categorical_crossentropy expects one-hot-encoded input\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "        np.array(X), np.array(y),\n",
    "        epochs=5000,\n",
    "        batch_size=10,\n",
    "        validation_split=0.12,\n",
    "        shuffle=True,\n",
    "        workers=10,\n",
    "        use_multiprocessing=True)\n",
    "\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------RUNNING THE MODEL----------------#\n",
    "\n",
    "def video_detector():\n",
    "    resultlist=[]\n",
    "    timestamps=[]\n",
    "    model = tf.keras.models.load_model(r\"C:\\\\Users\\\\Zoe Mercury\\\\Desktop\\\\Iron II\\\\A.I\\\\Untitled Folder\\\\model_small.h5\")  \n",
    "    face_cascade = cv2.CascadeClassifier(\"C:\\\\Users\\\\Zoe Mercury\\\\Desktop\\\\Iron II\\\\A.I\\\\Untitled Folder\\\\cropped\\\\haarcascade_frontalface_default.xml\") \n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    emotions = ('sad','happy','angry','excited')\n",
    "\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        frame = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
    "\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            roi_gray=frame[y:y+w,x:x+h]\n",
    "            roi_gray=cv2.resize(frame,(200,200))  \n",
    "            img_pixels = np.array(roi_gray)  / 255\n",
    "            img_pixels = np.expand_dims(img_pixels, axis = 0)  \n",
    "\n",
    "            predictions = model.predict(img_pixels)  \n",
    "            print(predictions)\n",
    "            max_index = np.argmax(predictions[0])  \n",
    "            print(max_index)\n",
    "            resultlist.append(max_index)\n",
    "            timestamps.append((datetime.now()))\n",
    "            d= {'Video Prediction': resultlist,'Time':timestamps}\n",
    "            df = pd.DataFrame(d, columns=['Video Prediction','Time'])\n",
    "\n",
    "            predicted_emotion = emotions[max_index] + ' '+ str(int(predictions[0][max_index]*100)) +'%'\n",
    "\n",
    "            cv2.putText(img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)  \n",
    "\n",
    "\n",
    "        cv2.imshow('img',img)\n",
    "\n",
    "        if cv2.waitKey(10) == ord('q'):\n",
    "            break  \n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelization of Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "p1 = multiprocessing.Process(target = video_detector, args = [2])\n",
    "p2 = multiprocessing.Process(target = eeg_detector, args = [2])\n",
    "\n",
    "p1.start()\n",
    "p2.start()\n",
    "\n",
    "p1.join()\n",
    "p2.join()\n",
    "\n",
    "finish = time.perf_counter()\n",
    "print('finished in ' + str(finish-start)+' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pokerface or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------COMPARE RESULTS----------------\n",
    "\n",
    "df.merge(comparison,on='Time')\n",
    "\n",
    "if df['EEG Prediction']==df['Video Prediction']:\n",
    "    print('You are honest!')\n",
    "else:\n",
    "    print('Mismatch of Emotion and Facial Expression!')\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
